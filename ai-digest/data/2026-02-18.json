{
  "date": "2026-02-18",
  "summary": "今日 AI 圈热点：Claude Sonnet 4.6 以 Sonnet 价格实现 Opus 性能；阿里 Qwen3.5-397B-A17B 开源发布（MoE 架构效率优势显著）；Gary Marcus 发文质疑 AGI 炒作；开源社区出现 BarraCUDA（让 CUDA 代码跑在 AMD GPU）；配置 AI Agent 系统的难题有了学习方案 ARC。中文视角：2026 国产大模型密集上新，Qwen3.5 原生多模态架构创新，智源发布世界模型趋势报告，从「预测下一个词」进化到「预测世界下一个状态」。",
  "articles": [
    {
      "num": 1,
      "title": "Claude Sonnet 4.6 发布：Opus 性能、Sonnet 价格",
      "url": "https://www.anthropic.com/news/claude-sonnet-4-6",
      "source": "Anthropic",
      "tldr": "Anthropic 今日发布 Sonnet 4.6，官方声称性能接近去年 11 月的 Opus 4.5，但定价维持 Sonnet 级别（输入 $3/百万 token，输出 $15/百万）。对比 Opus 的 $5/$25，成本效益显著提升。适合需要高质量输出但预算敏感的场景。",
      "tags": ["模型发布", "Anthropic"]
    },
    {
      "num": 2,
      "title": "Qwen3.5-397B-A17B：阿里开源 MoE 架构效率突破",
      "url": "https://qwen.ai/blog?id=qwen3.5",
      "source": "Alibaba Qwen Team",
      "tldr": "阿里发布 Qwen 3.5 系列首批两款模型（开源 397B-A17B MoE + 闭源版本），均支持视觉多模态输入。开源版采用混合专家架构（397B 总参数，17B 激活），官方强调「服务效率」是 MoE 的核心优势。这是继 DeepSeek 后又一个中国厂商用效率路线挑战参数规模竞赛的信号。",
      "tags": ["模型发布", "开源", "中国"]
    },
    {
      "num": 3,
      "title": "Gary Marcus：AGI 到来的传言被严重夸大",
      "url": "https://garymarcus.substack.com/p/rumors-of-agis-arrival-have-been",
      "source": "Gary Marcus Substack",
      "tldr": "Gary Marcus 发文驳斥近期 AGI 即将到来的炒作，核心论点：统计近似 ≠ 通用智能。他认为当前大模型本质上仍是「预测下一个 token」的统计系统，距离真正的推理、规划、泛化能力还有巨大鸿沟。这篇文章是对行业过度乐观情绪的清醒提醒。",
      "tags": ["观点", "AGI", "批判性思考"]
    },
    {
      "num": 4,
      "title": "BarraCUDA：开源 CUDA 编译器瞄准 AMD GPU",
      "url": "https://github.com/Zaneham/BarraCUDA",
      "source": "GitHub (HN 157 分)",
      "tldr": "社区开发者推出 BarraCUDA，允许 CUDA 代码直接编译到 AMD GPU。这对打破 NVIDIA 生态锁定有重要意义——大量 CUDA 项目无需重写即可利用 AMD 硬件。虽然性能和兼容性仍需验证，但方向值得关注，尤其在算力成本压力下。",
      "tags": ["开源", "GPU", "算力"]
    },
    {
      "num": 5,
      "title": "ARC：学习如何配置 AI Agent 系统",
      "url": "https://huggingface.co/papers/2602.11574",
      "source": "HuggingFace Paper (8 upvotes)",
      "tldr": "配置 LLM Agent 系统（工作流、工具、token 预算、prompt）通常靠人工调参或固定模板，导致资源浪费（简单查询用复杂配置）。ARC 提出将配置视为「按查询决策」问题，用强化学习动态选择最优配置。这是 Agent 工程化的重要一步：从手工艺到自动化优化。",
      "tags": ["论文", "Agent", "优化"]
    },
    {
      "num": 6,
      "title": "智源 2026 十大 AI 趋势：从预测词到预测世界状态",
      "url": "https://so.html5.qq.com/page/real/search_news?docid=70000021_525695f785401052",
      "source": "智源研究院",
      "tldr": "北京智源发布 2026 趋势报告，核心观点：AI 范式从「Next-Token Prediction」进化到「Next-State Prediction」（NSP）。这意味着从语言统计建模转向物理世界建模（世界模型）。具身智能、多模态世界模型成为新焦点，但商业化仍面临算法泛化难题。",
      "tags": ["趋势报告", "中国", "世界模型"]
    },
    {
      "num": 7,
      "title": "国产大模型春节密集上新：Qwen3.5/GLM-5/Kimi-K3/DeepSeek-V4",
      "url": "https://www.toutiao.com/article/7607317414367330870/",
      "source": "今日头条",
      "tldr": "2 月春节前后，国内大模型厂商集中发布新品：字节豆包 2.0、智谱 GLM-5（744B 参数）、MiniMax M2.5、阿里 Qwen3.5（除夕开源）、月之暗面 Kimi-K3、DeepSeek-V4 预告。券商认为 2026 年国产模型将「对标海外、价格优势明显」，可能重塑全球竞争格局。港股 AI 概念股因此大涨。",
      "tags": ["中国", "模型发布", "市场"]
    },
    {
      "num": 8,
      "title": "Open models in perpetual catch-up（开源模型永远在追赶）",
      "url": "https://www.interconnects.ai/p/open-models-in-perpetual-catch-up",
      "source": "Interconnects.ai",
      "tldr": "Nathan Lambert 深度分析开源-闭源差距、蒸馏技术、创新时间尺度等话题。核心观点：开源模型靠蒸馏追赶闭源，但创新总是滞后；真正的突破需要独立技术路线（如 DeepSeek 的效率创新）而非简单复刻。对开源社区来说，这是一个清醒的提醒。",
      "tags": ["观点", "开源", "分析"]
    },
    {
      "num": 9,
      "title": "Jeff Geerling：AI 正在摧毁开源（但它还不够好）",
      "url": "https://www.jeffgeerling.com/blog/2026/ai-is-destroying-open-source/",
      "source": "Jeff Geerling 博客",
      "tldr": "开源维护者 Jeff Geerling 痛批 AI 工具带来的副作用：低质量 PR、幻觉引用、自动生成的垃圾内容让维护者不堪重负。他引用 Ars Technica 撤稿事件（AI 捏造引用）和自己的遭遇，指出 AI 加速开发的同时也在制造「认知债务」。活人味十足的警示文章。",
      "tags": ["观点", "开源", "批判性思考"]
    },
    {
      "num": 10,
      "title": "Sub-Millisecond RAG on Apple Silicon (单文件、无服务器)",
      "url": "https://github.com/christopherkarani/Wax",
      "source": "GitHub (HN 85 分)",
      "tldr": "开发者发布 Wax，在 Apple Silicon 上实现亚毫秒级 RAG（检索增强生成），无需服务器、无需 API，单个文件搞定。这对本地 AI 应用开发者是福音：低延迟、隐私保护、零成本。虽然是小项目，但体现了「边缘 AI」的实用价值。",
      "tags": ["开源", "RAG", "Apple Silicon"]
    }
  ]
}
