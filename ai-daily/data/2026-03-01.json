{
  "date": "2026-03-01",
  "summary": "本周AI圈最大的震动不是某个新模型，而是资本与权力的双重收割：OpenAI完成史上最大私募融资$110B，同时签署军事机密网络部署协议；Anthropic则被Trump政府封禁，在「要不要给战争机器卖铲子」这件事上两家态度泾渭分明。技术侧，Qwen3.5开源模型本地可跑Sonnet 4.5水准，Claude登顶美国App Store——大模型民用化渗透速度超出预期。",
  "articles": [
    {
      "num": 1,
      "title": "OpenAI完成$110B融资：Amazon、英伟达、软银入局，估值$840B",
      "url": "https://www.latent.space/p/ainews-openai-closes-110b-raise-from",
      "source": "Latent Space (AINews)",
      "tldr": "OpenAI以$840B估值完成史上最大私募融资，Amazon、NVIDIA、SoftBank是主要投资方。Latent Space做了详尽的背景分析：这笔钱的用途、与微软关系的演变、以及Sam Altman在此轮结构中的话语权。融资背后是AGI竞赛的军备逻辑——不融就掉队，融了就背上更重的期望包袱。",
      "tags": ["OpenAI", "融资", "产业"]
    },
    {
      "num": 2,
      "title": "OpenAI与「战争部」签协议：AI模型将接入美国军事机密网络",
      "url": "https://openai.com/index/our-agreement-with-the-department-of-war",
      "source": "OpenAI Official",
      "tldr": "OpenAI正式宣布与美国国防部（「战争部」）合作，将旗下模型部署到军方机密网络。Sam Altman本人在Twitter上公开背书这一决定。这是OpenAI从「不作恶」转向「拥抱国家机器」的标志性时刻，也是其商业化扩张不可回避的边界测试。",
      "tags": ["OpenAI", "军事", "政策"]
    },
    {
      "num": 3,
      "title": "Anthropic回应「战争部长」言论：我们不应被列为供应链风险",
      "url": "https://www.anthropic.com/news/statement-comments-secretary-war",
      "source": "Anthropic",
      "tldr": "Hegseth公开点名质疑Anthropic是否构成政府供应链安全风险，Anthropic随即发表声明反驳，措辞克制但立场明确。与OpenAI主动拥抱军方相反，Anthropic在这场博弈中扮演了「拒绝接单」的角色，两家公司的路线分歧至此基本公开化。",
      "tags": ["Anthropic", "政策", "安全"]
    },
    {
      "num": 4,
      "title": "Trump封禁Anthropic：禁止在政府系统中使用",
      "url": "https://www.npr.org/2026/02/27/nx-s1-5729118/trump-anthropic-pentagon-openai-ai-weapons-ban",
      "source": "NPR",
      "tldr": "Trump政府正式将Anthropic列入政府禁用名单，原因据报道与安全立场和政治倾向有关。这是科技公司和政治权力直接碰撞的典型案例：Anthropic坚守Constitutional AI原则，结果在华盛顿的棋局里成了被踢出局的棋子。对AI公司的政治中立神话是一次直接击穿。",
      "tags": ["Anthropic", "政策", "Trump"]
    },
    {
      "num": 5,
      "title": "Qwen3.5开源发布：本地可跑Sonnet 4.5水准，122B和35B两款",
      "url": "https://venturebeat.com/technology/alibabas-new-open-source-qwen3-5-medium-models-offer-sonnet-4-5-performance",
      "source": "VentureBeat",
      "tldr": "阿里巴巴Qwen3.5 122B和35B模型开源发布，基准测试显示在多项任务上达到Claude Sonnet 4.5同等水平，且可在本地消费级硬件上运行。这意味着Sonnet级能力不再是Claude的专属壁垒——开源模型正在快速压缩顶级闭源模型的护城河，自托管路线开始变得务实可行。",
      "tags": ["Qwen", "开源", "Alibaba"]
    },
    {
      "num": 6,
      "title": "Claude登顶美国App Store第一，超越ChatGPT",
      "url": "https://apps.apple.com/us/iphone/charts",
      "source": "Hacker News",
      "tldr": "Claude iOS应用登上美国App Store免费榜第一，正式超过ChatGPT。这不只是一个排名数字——它说明Anthropic的消费者端渗透策略开始奏效，用户认知正在从「ChatGPT = AI」向多极分化演变。配合Claude Max面向开源维护者免费开放，Anthropic的用户增长策略正在多点开花。",
      "tags": ["Claude", "Anthropic", "用户增长"]
    },
    {
      "num": 7,
      "title": "AI编程Agent怀疑论者的亲测实录：Simon Willison万字深度评测",
      "url": "https://simonwillison.net/2026/Feb/27/ai-agent-coding-in-excessive-detail/#atom-everything",
      "source": "Simon Willison",
      "tldr": "向来对AI编程工具持审慎态度的Simon Willison，这次认真坐下来系统性地测了AI Agent编程工作流，并以「excessive detail」的方式记录了整个过程。文章不是无脑吹捧，也不是反射弧式的否定，而是有上下文的真实使用体验——这类「诚实评测」的稀缺性远大于又一篇生产力宣传文章。",
      "tags": ["AI编程", "Agent", "评测"]
    },
    {
      "num": 8,
      "title": "我们如何把MCP输出削减98%：别烧你的Context Window",
      "url": "https://mksg.lu/blog/context-mode",
      "source": "mksg.lu",
      "tldr": "这篇工程博客讲了一个实打实的优化问题：MCP工具返回的冗余输出会快速吞噬Context Window，导致模型在复杂任务中提前失忆。作者分享了他们通过「context mode」将MCP输出缩减98%的具体方案。任何在生产环境跑AI Agent的人都应该读这篇——context管理是目前最容易被忽视的性能瓶颈之一。",
      "tags": ["MCP", "工程", "Context优化"]
    },
    {
      "num": 9,
      "title": "OpenAI这轮$110B融资的逻辑站得住脚吗？Gary Marcus的质疑",
      "url": "https://garymarcus.substack.com/p/does-openais-new-financing-make-sense",
      "source": "Gary Marcus (Substack)",
      "tldr": "Gary Marcus从财务和技术两个角度质疑OpenAI这轮融资的合理性：$840B的估值建立在哪些假设之上？通往AGI的路线图能否支撑这个数字？Marcus的批评一贯锋利，这篇也不例外——他不是说OpenAI会失败，而是说当前的估值定价包含了太多的信仰溢价。",
      "tags": ["OpenAI", "融资", "批评"]
    },
    {
      "num": 10,
      "title": "METR研究员谈AI时间视野评估：如何衡量AI真实自主能力边界",
      "url": "https://www.latent.space/p/metr",
      "source": "Latent Space",
      "tldr": "METR的Joel Becker详细讲解了「Time Horizon Eval」方法论——通过测量AI Agent能独立完成多长时间跨度任务，来评估其真实自主能力。这不是理论讨论，而是直接指向当前AI安全评估体系的核心缺口：我们如何判断一个Agent是否真正达到了需要更严格监管的能力阈值？对做AI产品和安全研究的人都有参考价值。",
      "tags": ["AI安全", "评估", "METR"]
    }
  ]
}
