{
  "date": "2026-02-15",
  "summary": "今天 AI 圈最大的新闻是 GPT-5.2 在理论物理领域推导出新结果，标志着 AI 辅助科学发现进入新阶段。同时 MiniMax M2.5 开源以 1/20 成本匹配 Claude Opus，开源社区又多了一个重量级选手。Anthropic CEO Dario Amodei 警告我们距离 AGI 可能只有 1-3 年。",
  "articles": [
    {
      "num": 1,
      "title": "GPT-5.2 在理论物理领域推导出新结果",
      "url": "https://openai.com/index/new-result-theoretical-physics/",
      "source": "OpenAI Blog",
      "tldr": "GPT-5.2 Pro 首次发现单负螺旋度胶子树振幅在特殊动量空间切片中非零，推翻了教科书论断。模型花 12 小时推理证明，结果已通过验证。",
      "excerpt": "GPT-5.2 Pro mode was given a set of complex hand-calculated expressions for gluon tree amplitudes. The model identified patterns that human physicists had missed, conjecturing that single-negative-helicity amplitudes are nonzero on a special slice of momentum space.\n\nThis overturns a textbook result that had been accepted for decades. The model used its internal scaffolding to construct a 12-hour reasoning chain, effectively proving the conjecture through recursive relations and soft theorem verification.\n\nThis represents a milestone in AI-assisted scientific discovery — not just pattern matching, but genuine mathematical reasoning leading to new theoretical physics results.",
      "tags": ["研究", "模型发布"]
    },
    {
      "num": 2,
      "title": "MiniMax M2.5 开源：1/20 成本匹配 Claude Opus 4.6",
      "url": "https://winbuzzer.com/2026/02/14/minimax-m25-open-source-ai-model-claude-opus-cost-xcxwbn/",
      "source": "WinBuzzer",
      "tldr": "MiniMax 开源 M2.5（230B MoE，激活 10B），SWE-Bench Verified 达 80.2% 与 Claude Opus 持平，API 定价仅 $0.30-2.40/M tokens。",
      "excerpt": "Chinese AI startup MiniMax has open-sourced M2.5, a 230 billion parameter Mixture-of-Experts language model that activates only 10B parameters per inference. On SWE-Bench Verified, it scores 80.2%, matching Claude Opus 4.6.\n\nThe model was trained using MiniMax's Forge RL framework across 200,000+ real-world environments. API pricing comes in at $0.30-2.40 per million tokens — roughly 1/20th the cost of comparable models.\n\nAt 100 tokens per second throughput, the cost works out to approximately $1/hour, making it one of the most cost-efficient frontier-class models available.",
      "tags": ["开源", "模型发布"]
    },
    {
      "num": 3,
      "title": "Anthropic vs OpenAI：两种快速推理模式的技术内幕",
      "url": "https://seangoedecke.com/fast-llm-inference/",
      "source": "seangoedecke.com",
      "tldr": "Anthropic 降低批处理大小提速 2.5 倍（完整 Opus 4.6），成本增 6 倍；OpenAI 用 Cerebras 巨型芯片实现 15 倍提速，推出蒸馏版 Spark。",
      "excerpt": "Both labs launched fast inference modes simultaneously, but the technical approaches diverge sharply. Anthropic reduces batch sizes to achieve 2.5x speedup while running the full Opus 4.6 model — paying 6x more in compute per token.\n\nOpenAI partnered with Cerebras, using their 70-square-inch wafer-scale chips to achieve 15x throughput improvement. However, they ship a distilled model (Spark) rather than the full GPT-5.3, trading some capability for massive speed gains.\n\nThe philosophical difference is telling: Anthropic prioritizes model quality, OpenAI prioritizes user experience and latency.",
      "tags": ["深度分析", "工程"]
    }
  ]
}
